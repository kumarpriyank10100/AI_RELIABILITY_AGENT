{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: The Setup (Run this first)\n",
        "\n",
        "This cell installs the libraries and sets up your Gemini connection."
      ],
      "metadata": {
        "id": "Z6NoaZ9Rnw4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q -U google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Setup Gemini - Paste your API Key from AI Studio here\n",
        "from google.colab import userdata\n",
        "try:\n",
        "    # If you saved it in Colab Secrets\n",
        "    API_KEY = userdata.get('GEMINI_KEY')\n",
        "except:\n",
        "    # Or just paste it directly for now:\n",
        "    API_KEY = \"AIzaSyAOFlZgeRj3CJgzpE4kg7k0oRIVkBYlZsw\"\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "model_gemini = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDa-Xswynw5F",
        "outputId": "ffcc4e7f-ec31-43cc-acfb-5e6255590ab7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Step 2: Simulated Chemical Plant Data & ML Training\n",
        "\n",
        "This cell creates the \"Physics\" of your plant. We are simulating a **CSTR** where high temperatures and pressures indicate a \"Runaway Reaction\" fault."
      ],
      "metadata": {
        "id": "6Ix7HDo9nw5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generate Synthetic CSTR Data\n",
        "np.random.seed(42)\n",
        "data_size = 1200\n",
        "temp = np.random.normal(350, 25, data_size)   # Kelvin\n",
        "press = np.random.normal(100, 20, data_size)  # psi\n",
        "flow = np.random.normal(50, 10, data_size)    # L/min\n",
        "\n",
        "# Fault Label: 1 if it's an exothermic runaway, else 0\n",
        "# Logic: If Temp > 385K and Pressure > 140psi\n",
        "target = ((temp > 385) & (press > 140)).astype(int)\n",
        "df = pd.DataFrame({'temp': temp, 'press': press, 'flow': flow, 'target': target})\n",
        "\n",
        "# 2. Train the Fault Predictor (The 'Brain')\n",
        "X = df[['temp', 'press', 'flow']]\n",
        "y = df['target']\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Save it to the Colab environment\n",
        "joblib.dump(clf, 'cstr_model.pkl')\n",
        "print(\"✅ Plant Physics Model Trained and Saved.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Plant Physics Model Trained and Saved.\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DP-ENdmnw5N",
        "outputId": "75c537b3-9412-4fd6-ae25-3ec771ae8c90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Step 3: The Knowledge Base (SOPs)\n",
        "\n",
        "In a real plant, you have manuals. We will store these in a JSON format."
      ],
      "metadata": {
        "id": "-5x-7E_Xnw5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sops = {\n",
        "    \"Emergency_Procedures\": {\n",
        "        \"High_Heat_Fault\": \"CRITICAL: Exothermic runaway suspected. ACTION: Increase coolant flow to max. If pressure > 150psi, open emergency vent V-301. DO NOT close the outlet valve.\",\n",
        "        \"Normal_Ops\": \"System stable. Maintain current setpoints.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('plant_sops.json', 'w') as f:\n",
        "    json.dump(sops, f)\n",
        "print(\"✅ Knowledge Base (SOPs) Created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Knowledge Base (SOPs) Created.\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfUoMPY0nw5R",
        "outputId": "83d3e7fe-c85e-4369-fb33-ce816b4cae89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Step 4: The Agentic Loop\n",
        "\n",
        "This is the core of the project. It takes sensor data, predicts the state, consults the SOPs, asks the AI for advice, and then runs a **Safety Check**."
      ],
      "metadata": {
        "id": "GWEE4GLCnw5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safety_interlock(temp, press, ai_advice):\n",
        "    \"\"\"The 'Physics-Informed' Safety Guardrail\"\"\"\n",
        "    if press > 150 and any(word in ai_advice.lower() for word in [\"close\", \"shut\"]) and \"vent\" in ai_advice.lower():\n",
        "        return \"⚠️ CRITICAL REJECTION: AI suggested closing vent during high pressure. Interlock forced VENT OPEN.\"\n",
        "    return \"✅ SAFETY CLEARED\"\n",
        "\n",
        "def run_agentic_pdm(current_temp, current_press, current_flow):\n",
        "    # 1. Predictive Step (Fixing the Feature Name warning)\n",
        "    input_data = pd.DataFrame([[current_temp, current_press, current_flow]],\n",
        "                               columns=['temp', 'press', 'flow'])\n",
        "    prediction = clf.predict(input_data)[0]\n",
        "    status = \"High_Heat_Fault\" if prediction == 1 else \"Normal_Ops\"\n",
        "\n",
        "    # 2. Retrieve SOP\n",
        "    relevant_sop = sops[\"Emergency_Procedures\"][status]\n",
        "\n",
        "    # 3. Agentic Reasoning (The LLM - with fixed model string)\n",
        "    # Using 'gemini-1.5-flash' specifically\n",
        "    prompt = f\"\"\"\n",
        "    You are a Chemical Process Engineer.\n",
        "    CURRENT SENSORS: Temp {current_temp}K, Pressure {current_press}psi, Flow {current_flow}L/min.\n",
        "    ML DETECTION: {status}\n",
        "    OFFICIAL SOP: {relevant_sop}\n",
        "\n",
        "    Explain the danger (if any) and give one clear command to the operator.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model_gemini.generate_content(prompt)\n",
        "        ai_response = response.text\n",
        "    except Exception as e:\n",
        "        ai_response = f\"Error calling Gemini: {str(e)}\"\n",
        "\n",
        "    # 4. Safety Verification\n",
        "    safety_status = safety_interlock(current_temp, current_press, ai_response)\n",
        "\n",
        "    # Display Results\n",
        "    print(f\"--- SENSOR INPUT: Temp={current_temp}K, Press={current_press}psi ---\")\n",
        "    print(f\"AI ANALYSIS: {ai_response}\")\n",
        "    print(f\"INTERLOCK STATUS: {safety_status}\\n\")\n",
        "\n",
        "# --- TEST THE SYSTEM ---\n",
        "print(\"Testing Normal Ops...\")\n",
        "run_agentic_pdm(350, 100, 50)\n",
        "\n",
        "print(\"Testing Runaway Scenario...\")\n",
        "run_agentic_pdm(400, 160, 45)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "UBkGilhKs5LB",
        "outputId": "7427314f-ac78-461c-c6b7-4e3864652e0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Normal Ops...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 1443.63ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SENSOR INPUT: Temp=350K, Press=100psi ---\n",
            "AI ANALYSIS: Error calling Gemini: 404 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
            "INTERLOCK STATUS: ✅ SAFETY CLEARED\n",
            "\n",
            "Testing Runaway Scenario...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 608.39ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SENSOR INPUT: Temp=400K, Press=160psi ---\n",
            "AI ANALYSIS: Error calling Gemini: 404 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
            "INTERLOCK STATUS: ✅ SAFETY CLEARED\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}